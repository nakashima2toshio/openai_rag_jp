# ğŸ“‹ helper_api.py è¨­è¨ˆæ›¸

## ğŸ“ ç›®æ¬¡

1. [ğŸ“– æ¦‚è¦æ›¸](#ğŸ“–-æ¦‚è¦æ›¸)
2. [ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ](#ğŸ”§-ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ)
3. [ğŸ“‹ é–¢æ•°ä¸€è¦§](#ğŸ“‹-é–¢æ•°ä¸€è¦§)
4. [ğŸ“‘ é–¢æ•°è©³ç´°è¨­è¨ˆ](#ğŸ“‘-é–¢æ•°è©³ç´°è¨­è¨ˆ)
5. [âš™ï¸ æŠ€è¡“ä»•æ§˜](#âš™ï¸-æŠ€è¡“ä»•æ§˜)
6. [ğŸš¨ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°](#ğŸš¨-ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°)

---

## ğŸ“– æ¦‚è¦æ›¸

### ğŸ¯ å‡¦ç†ã®æ¦‚è¦

**OpenAI APIé–¢é€£ã¨ã‚³ã‚¢æ©Ÿèƒ½ãƒ©ã‚¤ãƒ–ãƒ©ãƒª**

helper_api.pyã¯ã€OpenAI APIã¨ã®é€£æºã‚’è¡Œã†ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å‘ã‘ã®åŒ…æ‹¬çš„ãªã‚³ã‚¢æ©Ÿèƒ½ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚APIé€šä¿¡ã€è¨­å®šç®¡ç†ã€ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç®¡ç†ãªã©ã€OpenAI APIã‚’æ´»ç”¨ã—ãŸã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹ç™ºã«å¿…è¦ãªåŸºç›¤æ©Ÿèƒ½ã‚’çµ±ä¸€çš„ã«æä¾›ã—ã¾ã™ã€‚

#### ğŸŒŸ ä¸»è¦æ©Ÿèƒ½ã‚«ãƒ†ã‚´ãƒª

| ã‚«ãƒ†ã‚´ãƒª | æ©Ÿèƒ½ç¾¤ | èª¬æ˜ |
|---------|--------|------|
| âš™ï¸ **è¨­å®šç®¡ç†** | ConfigManager | YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ç’°å¢ƒå¤‰æ•°ã«ã‚ˆã‚‹çµ±ä¸€è¨­å®šç®¡ç† |
| ğŸ’¾ **ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ** | MemoryCache | ãƒ¡ãƒ¢ãƒªãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚ˆã‚‹åŠ¹ç‡åŒ– |
| ğŸ“Š **JSONå‡¦ç†** | safe_json_* | OpenAI APIãƒ¬ã‚¹ãƒãƒ³ã‚¹å¯¾å¿œã®å®‰å…¨ãªJSONå‡¦ç† |
| ğŸ”§ **ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿** | error_handlerãƒ»timerãƒ»cache_result | æ¨ªæ–­çš„æ©Ÿèƒ½ã®åŠ¹ç‡çš„ãªé©ç”¨ |
| ğŸ’¬ **ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç®¡ç†** | MessageManager | ä¼šè©±å±¥æ­´ãƒ»ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç† |
| ğŸ”¢ **ãƒˆãƒ¼ã‚¯ãƒ³ç®¡ç†** | TokenManager | ç²¾å¯†ãªãƒˆãƒ¼ã‚¯ãƒ³è¨ˆç®—ãƒ»ã‚³ã‚¹ãƒˆæ¨å®š |
| ğŸ“‹ **ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†** | ResponseProcessor | APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å®‰å…¨ãªå‡¦ç†ãƒ»ä¿å­˜ |
| ğŸ¤– **APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ** | OpenAIClient | Responses APIãƒ»Chat Completions APIçµ±ä¸€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ |

#### ğŸ”„ APIå‡¦ç†ãƒ•ãƒ­ãƒ¼

```mermaid
graph TD
    A["Config Loading"] --> B["API Client Initialize"]
    B --> C["Message Management"]
    C --> D["Token Calculation"]
    D --> E["Cache Check"]
    E --> F["API Request"]
    F --> G["Response Processing"]
    G --> H["Cache Storage"]
    H --> I["Result Return"]
```

### ğŸ”„ ä¸»è¦å‡¦ç†ã®æµã‚Œï¼ˆOpenAI APIé€£æºï¼‰

```mermaid
flowchart TD
    Start(["Application Start"]) --> Config["ConfigManager Initialize (Singleton)"]
    Config --> Cache["MemoryCache Setup"]
    Cache --> Client["OpenAIClient Initialize"]
    Client --> Message["MessageManager Setup"]

    Message --> Request["API Request Preparation"]
    Request --> Token["TokenManager Calculation"]
    Token --> Send["API Call (Responses/Chat)"]
    Send --> Process["ResponseProcessor Handle"]

    Process --> Store["Cache Storage"]
    Store --> Save["Response Saving"]
    Save --> End(["API Response Complete"])
```

---

## ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ

### ğŸ“¦ ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

```mermaid
classDiagram
    class ConfigManager {
        +_instance: ConfigManager
        +config_path: Path
        +_config: dict
        +_cache: dict
        +logger: Logger
        +get()
        +set()
        +reload()
        +save()
    }

    class MemoryCache {
        +_storage: dict
        +_enabled: bool
        +_ttl: int
        +_max_size: int
        +get()
        +set()
        +clear()
        +size()
    }

    class MessageManager {
        +_messages: List
        +add_message()
        +get_messages()
        +clear_messages()
        +export_messages()
        +import_messages()
    }

    class TokenManager {
        +MODEL_ENCODINGS: dict
        +count_tokens()
        +truncate_text()
        +estimate_cost()
        +get_model_limits()
    }

    class ResponseProcessor {
        +extract_text()
        +format_response()
        +save_response()
        +_serialize_usage()
    }

    class OpenAIClient {
        +client: OpenAI
        +create_response()
        +create_chat_completion()
    }

    ConfigManager --> MemoryCache
    ConfigManager --> TokenManager
    MessageManager --> TokenManager
    OpenAIClient --> ResponseProcessor
    ResponseProcessor --> ConfigManager
```

### ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ï¼ˆAPIå‡¦ç†ï¼‰

```mermaid
graph TD
    A["YAML Config File"] --> B["ConfigManager (Singleton)"]
    B --> C["Environment Variables Override"]
    C --> D["OpenAIClient Initialize"]
    D --> E["MessageManager Prepare"]
    E --> F["TokenManager Calculate"]
    F --> G["MemoryCache Check"]
    G --> H["API Request (OpenAI)"]
    H --> I["ResponseProcessor Handle"]
    I --> J["Safe JSON Serialization"]
    J --> K["Cache Storage & File Save"]
```

---

## ğŸ“‹ é–¢æ•°ä¸€è¦§

### âš™ï¸ è¨­å®šç®¡ç†ã‚¯ãƒ©ã‚¹

| é–¢æ•°å | åˆ†é¡ | å‡¦ç†æ¦‚è¦ | é‡è¦åº¦ |
|--------|------|----------|---------|
| `ConfigManager.__new__()` | ğŸ—ï¸ ç”Ÿæˆ | ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç®¡ç† | â­â­â­ |
| `ConfigManager.__init__()` | ğŸ›ï¸ åˆæœŸåŒ– | è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ãƒ»ãƒ­ã‚¬ãƒ¼è¨­å®š | â­â­â­ |
| `ConfigManager.get()` | ğŸ“Š å–å¾— | ãƒ‰ãƒƒãƒˆè¨˜æ³•ã«ã‚ˆã‚‹è¨­å®šå€¤å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰ | â­â­â­ |
| `ConfigManager.set()` | âœï¸ è¨­å®š | è¨­å®šå€¤ã®å‹•çš„æ›´æ–°ãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ | â­â­ |
| `ConfigManager.reload()` | ğŸ”„ å†èª­è¾¼ | è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å†èª­ã¿è¾¼ã¿ | â­â­ |
| `ConfigManager.save()` | ğŸ’¾ ä¿å­˜ | è¨­å®šã®YAMLãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ | â­â­ |
| `ConfigManager._load_config()` | ğŸ“¥ å†…éƒ¨ | YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å‡¦ç† | â­â­â­ |
| `ConfigManager._apply_env_overrides()` | ğŸ”„ å†…éƒ¨ | ç’°å¢ƒå¤‰æ•°ã«ã‚ˆã‚‹è¨­å®šã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ | â­â­â­ |
| `ConfigManager._get_default_config()` | ğŸ­ å†…éƒ¨ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã®ç”Ÿæˆ | â­â­ |

### ğŸ’¾ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ 

| é–¢æ•°å | åˆ†é¡ | å‡¦ç†æ¦‚è¦ | é‡è¦åº¦ |
|--------|------|----------|---------|
| `MemoryCache.get()` | ğŸ“Š å–å¾— | TTLä»˜ãã‚­ãƒ£ãƒƒã‚·ãƒ¥å€¤å–å¾— | â­â­â­ |
| `MemoryCache.set()` | ğŸ’¾ è¨­å®š | ã‚µã‚¤ã‚ºåˆ¶é™ä»˜ãã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ | â­â­â­ |
| `MemoryCache.clear()` | ğŸ—‘ï¸ ã‚¯ãƒªã‚¢ | å…¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ | â­â­ |
| `MemoryCache.size()` | ğŸ“ ã‚µã‚¤ã‚º | ç¾åœ¨ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºå–å¾— | â­ |

### ğŸ“Š JSONå‡¦ç†é–¢æ•°

| é–¢æ•°å | åˆ†é¡ | å‡¦ç†æ¦‚è¦ | é‡è¦åº¦ |
|--------|------|----------|---------|
| `safe_json_serializer()` | ğŸ”„ å¤‰æ› | OpenAI APIã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå¯¾å¿œã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¶ãƒ¼ | â­â­â­ |
| `safe_json_dumps()` | ğŸ“„ å‡ºåŠ› | å®‰å…¨ãªJSONæ–‡å­—åˆ—åŒ–ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰ | â­â­â­ |

### ğŸ”§ ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿é–¢æ•°

| é–¢æ•°å | åˆ†é¡ | å‡¦ç†æ¦‚è¦ | é‡è¦åº¦ |
|--------|------|----------|---------|
| `error_handler()` | ğŸ›¡ï¸ ã‚¨ãƒ©ãƒ¼ | APIç”¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ | â­â­â­ |
| `timer()` | â±ï¸ è¨ˆæ¸¬ | å®Ÿè¡Œæ™‚é–“è¨ˆæ¸¬ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ | â­â­ |
| `cache_result()` | ğŸ’¾ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ | çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ï¼ˆãƒ¡ãƒ¢ãƒªãƒ™ãƒ¼ã‚¹ï¼‰ | â­â­â­ |

### ğŸ’¬ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç®¡ç†ã‚¯ãƒ©ã‚¹

| é–¢æ•°å | åˆ†é¡ | å‡¦ç†æ¦‚è¦ | é‡è¦åº¦ |
|--------|------|----------|---------|
| `MessageManager.add_message()` | â• è¿½åŠ  | ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã¸ã®å®‰å…¨ãªè¿½åŠ  | â­â­â­ |
| `MessageManager.get_messages()` | ğŸ“Š å–å¾— | ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®ã‚³ãƒ”ãƒ¼å–å¾— | â­â­â­ |
| `MessageManager.clear_messages()` | ğŸ—‘ï¸ ã‚¯ãƒªã‚¢ | ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®ãƒªã‚»ãƒƒãƒˆ | â­â­ |
| `MessageManager.export_messages()` | ğŸ“¤ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ | ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®JSONå‡ºåŠ› | â­â­ |
| `MessageManager.import_messages()` | ğŸ“¥ ã‚¤ãƒ³ãƒãƒ¼ãƒˆ | ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®JSONèª­ã¿è¾¼ã¿ | â­â­ |
| `MessageManager.get_default_messages()` | ğŸ­ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”Ÿæˆ | â­â­ |

### ğŸ”¢ ãƒˆãƒ¼ã‚¯ãƒ³ç®¡ç†ã‚¯ãƒ©ã‚¹

| é–¢æ•°å | åˆ†é¡ | å‡¦ç†æ¦‚è¦ | é‡è¦åº¦ |
|--------|------|----------|---------|
| `TokenManager.count_tokens()` | ğŸ”¢ è¨ˆç®— | ç²¾å¯†ãªãƒˆãƒ¼ã‚¯ãƒ³æ•°è¨ˆç®—ï¼ˆtiktokenä½¿ç”¨ï¼‰ | â­â­â­ |
| `TokenManager.truncate_text()` | âœ‚ï¸ åˆ‡ã‚Šè©°ã‚ | æŒ‡å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°ã§ã®ãƒ†ã‚­ã‚¹ãƒˆåˆ‡ã‚Šè©°ã‚ | â­â­â­ |
| `TokenManager.estimate_cost()` | ğŸ’° æ¨å®š | ãƒ¢ãƒ‡ãƒ«åˆ¥APIä½¿ç”¨ã‚³ã‚¹ãƒˆæ¨å®š | â­â­â­ |
| `TokenManager.get_model_limits()` | ğŸ“Š åˆ¶é™ | ãƒ¢ãƒ‡ãƒ«åˆ¥ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™å–å¾— | â­â­â­ |

### ğŸ“‹ ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†ã‚¯ãƒ©ã‚¹

| é–¢æ•°å | åˆ†é¡ | å‡¦ç†æ¦‚è¦ | é‡è¦åº¦ |
|--------|------|----------|---------|
| `ResponseProcessor.extract_text()` | ğŸ“ æŠ½å‡º | Responseã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º | â­â­â­ |
| `ResponseProcessor.format_response()` | ğŸ¨ æ•´å½¢ | ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®JSON serializableå¤‰æ› | â­â­â­ |
| `ResponseProcessor.save_response()` | ğŸ’¾ ä¿å­˜ | ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰ | â­â­ |
| `ResponseProcessor._serialize_usage()` | ğŸ”„ å†…éƒ¨ | ResponseUsageã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®è¾æ›¸å¤‰æ› | â­â­â­ |

### ğŸ¤– APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¯ãƒ©ã‚¹

| é–¢æ•°å | åˆ†é¡ | å‡¦ç†æ¦‚è¦ | é‡è¦åº¦ |
|--------|------|----------|---------|
| `OpenAIClient.create_response()` | ğŸ†• API | Responses APIå‘¼ã³å‡ºã—ï¼ˆæ–°æ—§ä»•æ§˜å¯¾å¿œï¼‰ | â­â­â­ |
| `OpenAIClient.create_chat_completion()` | ğŸ’¬ API | Chat Completions APIå‘¼ã³å‡ºã— | â­â­â­ |

### ğŸ”§ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°

| é–¢æ•°å | åˆ†é¡ | å‡¦ç†æ¦‚è¦ | é‡è¦åº¦ |
|--------|------|----------|---------|
| `sanitize_key()` | ğŸ”¤ å¤‰æ› | ã‚­ãƒ¼æ–‡å­—åˆ—ã®å®‰å…¨åŒ–ï¼ˆæ­£è¦è¡¨ç¾ï¼‰ | â­â­ |
| `load_json_file()` | ğŸ“¥ èª­è¾¼ | å®‰å…¨ãªJSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ | â­â­ |
| `save_json_file()` | ğŸ’¾ ä¿å­˜ | å®‰å…¨ãªJSONãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ | â­â­ |
| `format_timestamp()` | ğŸ“… å¤‰æ› | ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®æ¨™æº–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ | â­ |
| `create_session_id()` | ğŸ†” ç”Ÿæˆ | ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚»ãƒƒã‚·ãƒ§ãƒ³IDç”Ÿæˆ | â­ |

### ğŸ­ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé–¢æ•°

| é–¢æ•°å | åˆ†é¡ | å‡¦ç†æ¦‚è¦ | é‡è¦åº¦ |
|--------|------|----------|---------|
| `get_default_messages()` | ğŸ“ ç”Ÿæˆ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚»ãƒƒãƒˆã®ç”Ÿæˆ | â­â­ |
| `append_user_message()` | â• è¿½åŠ  | ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¿½åŠ ç‰ˆã®ç”Ÿæˆ | â­â­ |
| `append_developer_message()` | â• è¿½åŠ  | é–‹ç™ºè€…ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¿½åŠ ç‰ˆã®ç”Ÿæˆ | â­â­ |
| `append_assistant_message()` | â• è¿½åŠ  | ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¿½åŠ ç‰ˆã®ç”Ÿæˆ | â­â­ |

---

## ğŸ“‘ é–¢æ•°è©³ç´°è¨­è¨ˆ

### âš™ï¸ ConfigManager.__new__()

#### ğŸ¯ å‡¦ç†æ¦‚è¦
ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚‹ConfigManagerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ä¸€æ„æ€§ä¿è¨¼

#### ğŸ“Š å‡¦ç†ã®æµã‚Œ
```mermaid
graph TD
    A["__new__ called"] --> B{"_instance exists?"}
    B -->|No| C["Create new instance"]
    B -->|Yes| D["Return existing instance"]
    C --> E["Store in _instance"]
    E --> F["Return instance"]
    D --> F
```

#### ğŸ“‹ IPOè¨­è¨ˆ

| é …ç›® | å†…å®¹ |
|------|------|
| **INPUT** | `cls: type` - ConfigManagerã‚¯ãƒ©ã‚¹<br>`config_path: str = "config.yml"` - è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ |
| **PROCESS** | ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å­˜åœ¨ç¢ºèª â†’ æ–°è¦ä½œæˆã¾ãŸã¯æ—¢å­˜è¿”å´ |
| **OUTPUT** | `ConfigManager` - ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ |

#### ğŸ”§ ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³å®Ÿè£…

```python
def __new__(cls, config_path: str = "config.yml"):
    if cls._instance is None:
        cls._instance = super().__new__(cls)
    return cls._instance
```

---

### ğŸ“Š ConfigManager.get()

#### ğŸ¯ å‡¦ç†æ¦‚è¦
ãƒ‰ãƒƒãƒˆè¨˜æ³•ã«ã‚ˆã‚‹éšå±¤è¨­å®šå€¤ã®å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ä»˜ãï¼‰

#### ğŸ“Š å‡¦ç†ã®æµã‚Œ
```mermaid
graph TD
    A["Function Start"] --> B{"Key in cache?"}
    B -->|Yes| C["Return cached value"]
    B -->|No| D["Split key by dots"]
    D --> E["Navigate config hierarchy"]
    E --> F["Apply default if None"]
    F --> G["Cache result"]
    G --> H["Return value"]
```

#### ğŸ“‹ IPOè¨­è¨ˆ

| é …ç›® | å†…å®¹ |
|------|------|
| **INPUT** | `key: str` - ãƒ‰ãƒƒãƒˆè¨˜æ³•è¨­å®šã‚­ãƒ¼ï¼ˆä¾‹: "api.timeout"ï¼‰<br>`default: Any = None` - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ |
| **PROCESS** | ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç¢ºèª â†’ éšå±¤ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ â†’ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé©ç”¨ â†’ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ |
| **OUTPUT** | `Any` - è¨­å®šå€¤ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ |

#### ğŸ” è¨­å®šå€¤å–å¾—ä¾‹

```python
# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¾‹
api:
  timeout: 30
  max_retries: 3
  openai_api_key: null

# å–å¾—ä¾‹
timeout = config.get("api.timeout", 60)          # â†’ 30
api_key = config.get("api.openai_api_key", "")   # â†’ ""
unknown = config.get("unknown.setting", "default") # â†’ "default"
```

---

### ğŸ’¾ MemoryCache.get()

#### ğŸ¯ å‡¦ç†æ¦‚è¦
TTLï¼ˆTime To Liveï¼‰æ©Ÿèƒ½ä»˜ããƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ã®å€¤å–å¾—

#### ğŸ“Š å‡¦ç†ã®æµã‚Œ
```mermaid
graph TD
    A["Function Start"] --> B{"Cache enabled?"}
    B -->|No| C["Return None"]
    B -->|Yes| D{"Key exists?"}
    D -->|No| C
    D -->|Yes| E["Check TTL expiry"]
    E -->|Expired| F["Delete key & Return None"]
    E -->|Valid| G["Return cached value"]
```

#### ğŸ“‹ IPOè¨­è¨ˆ

| é …ç›® | å†…å®¹ |
|------|------|
| **INPUT** | `key: str` - ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ |
| **PROCESS** | æœ‰åŠ¹æ€§ç¢ºèª â†’ TTLæœŸé™ç¢ºèª â†’ å€¤è¿”å´/å‰Šé™¤ |
| **OUTPUT** | `Any | None` - ã‚­ãƒ£ãƒƒã‚·ãƒ¥å€¤ã¾ãŸã¯None |

#### ğŸ”§ TTLç®¡ç†æ©Ÿèƒ½

```python
# ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ§‹é€ 
_storage = {
    "key": {
        "result": "cached_value",
        "timestamp": 1640995200.0
    }
}

# TTLç¢ºèª
if time.time() - cached_data['timestamp'] > self._ttl:
    del self._storage[key]
    return None
```

---

### ğŸ“Š safe_json_serializer()

#### ğŸ¯ å‡¦ç†æ¦‚è¦
OpenAI APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå¯¾å¿œã®ã‚«ã‚¹ã‚¿ãƒ JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¶ãƒ¼

#### ğŸ“Š å‡¦ç†ã®æµã‚Œ
```mermaid
graph TD
    A["Object to serialize"] --> B{"Has model_dump()?"}
    B -->|Yes| C["Use model_dump()"]
    B -->|No| D{"Has dict()?"}
    D -->|Yes| E["Use dict()"]
    D -->|No| F{"Is datetime?"}
    F -->|Yes| G["Convert to isoformat()"]
    F -->|No| H{"Has token attributes?"}
    H -->|Yes| I["Extract token usage"]
    H -->|No| J["Convert to string"]
```

#### ğŸ“‹ IPOè¨­è¨ˆ

| é …ç›® | å†…å®¹ |
|------|------|
| **INPUT** | `obj: Any` - ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯¾è±¡ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ |
| **PROCESS** | ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå‹åˆ¤å®š â†’ é©åˆ‡ãªå¤‰æ›æ–¹æ³•é¸æŠ â†’ è¾æ›¸/æ–‡å­—åˆ—å¤‰æ› |
| **OUTPUT** | `Any` - JSON serializable ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ |

#### ğŸ”§ å¯¾å¿œã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆç¨®åˆ¥

```python
å¯¾å¿œãƒ‘ã‚¿ãƒ¼ãƒ³:
1. Pydantic Model: obj.model_dump()
2. Dict Protocol: obj.dict()
3. Datetime: obj.isoformat()
4. OpenAI ResponseUsage: æ‰‹å‹•å±æ€§æŠ½å‡º
   {
       'prompt_tokens': obj.prompt_tokens,
       'completion_tokens': obj.completion_tokens,
       'total_tokens': obj.total_tokens
   }
5. ãã®ä»–: str(obj)
```

---

### ğŸ”§ error_handler()

#### ğŸ¯ å‡¦ç†æ¦‚è¦
APIç”¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ï¼ˆä¾‹å¤–å†ç™ºç”Ÿå‹ï¼‰

#### ğŸ“Š å‡¦ç†ã®æµã‚Œ
```mermaid
graph TD
    A["Function Call"] --> B["Try Execute"]
    B -->|Success| C["Return Result"]
    B -->|Exception| D["Log Error"]
    D --> E["Re-raise Exception"]
    C --> F["End"]
    E --> F
```

#### ğŸ“‹ IPOè¨­è¨ˆ

| é …ç›® | å†…å®¹ |
|------|------|
| **INPUT** | `func: Callable` - ãƒ‡ã‚³ãƒ¬ãƒ¼ãƒˆå¯¾è±¡é–¢æ•° |
| **PROCESS** | é–¢æ•°å®Ÿè¡Œ â†’ ä¾‹å¤–ã‚­ãƒ£ãƒƒãƒ â†’ ãƒ­ã‚°å‡ºåŠ› â†’ ä¾‹å¤–å†ç™ºç”Ÿ |
| **OUTPUT** | `Callable` - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãé–¢æ•° |

#### ğŸ›¡ï¸ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æˆ¦ç•¥

```python
@error_handler
def api_function():
    # APIå‡¦ç†
    pass

# è‡ªå‹•é©ç”¨ã•ã‚Œã‚‹å‡¦ç†:
try:
    return api_function()
except Exception as e:
    logger.error(f"Error in api_function: {str(e)}")
    raise  # APIç”¨ã§ã¯ä¾‹å¤–ã‚’å†ç™ºç”Ÿ
```

---

### â±ï¸ timer()

#### ğŸ¯ å‡¦ç†æ¦‚è¦
é–¢æ•°å®Ÿè¡Œæ™‚é–“ã®è¨ˆæ¸¬ãƒ»ãƒ­ã‚°å‡ºåŠ›ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿

#### ğŸ“Š å‡¦ç†ã®æµã‚Œ
```mermaid
graph TD
    A["Function Call"] --> B["Record start_time"]
    B --> C["Execute function"]
    C --> D["Record end_time"]
    D --> E["Calculate execution_time"]
    E --> F["Log timing info"]
    F --> G["Return result"]
```

#### ğŸ“‹ IPOè¨­è¨ˆ

| é …ç›® | å†…å®¹ |
|------|------|
| **INPUT** | `func: Callable` - è¨ˆæ¸¬å¯¾è±¡é–¢æ•° |
| **PROCESS** | é–‹å§‹æ™‚åˆ»è¨˜éŒ² â†’ é–¢æ•°å®Ÿè¡Œ â†’ çµ‚äº†æ™‚åˆ»è¨˜éŒ² â†’ å®Ÿè¡Œæ™‚é–“è¨ˆç®—ãƒ»ãƒ­ã‚° |
| **OUTPUT** | `Callable` - å®Ÿè¡Œæ™‚é–“è¨ˆæ¸¬ä»˜ãé–¢æ•° |

#### â±ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–

```python
@timer
def slow_api_call():
    # é‡ã„å‡¦ç†
    pass

# ãƒ­ã‚°å‡ºåŠ›ä¾‹:
# INFO - slow_api_call took 2.34 seconds
```

---

### ğŸ’¾ cache_result()

#### ğŸ¯ å‡¦ç†æ¦‚è¦
é–¢æ•°çµæœã®ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥åŒ–ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿

#### ğŸ“Š å‡¦ç†ã®æµã‚Œ
```mermaid
graph TD
    A["Function Call"] --> B{"Cache enabled?"}
    B -->|No| C["Execute function"]
    B -->|Yes| D["Generate cache key"]
    D --> E{"Cache hit?"}
    E -->|Yes| F["Return cached result"]
    E -->|No| G["Execute function"]
    G --> H["Cache result"]
    H --> I["Return result"]
```

#### ğŸ“‹ IPOè¨­è¨ˆ

| é …ç›® | å†…å®¹ |
|------|------|
| **INPUT** | `ttl: int = None` - TTLè¨­å®šï¼ˆæœªä½¿ç”¨ï¼‰<br>`func: Callable` - ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾è±¡é–¢æ•° |
| **PROCESS** | ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ç”Ÿæˆ â†’ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç¢ºèª â†’ é–¢æ•°å®Ÿè¡Œ/ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¿”å´ |
| **OUTPUT** | `Callable` - ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ä»˜ãé–¢æ•° |

#### ğŸ”‘ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ç”Ÿæˆ

```python
# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯
cache_key = f"{func.__name__}_{hashlib.md5(str(args).encode() + str(kwargs).encode()).hexdigest()}"

# ä¾‹: get_user_data(123, active=True)
# â†’ "get_user_data_a1b2c3d4e5f6..."
```

---

### ğŸ’¬ MessageManager.add_message()

#### ğŸ¯ å‡¦ç†æ¦‚è¦
ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã¸ã®å®‰å…¨ãªè¿½åŠ ï¼ˆå‹æ¤œè¨¼ãƒ»åˆ¶é™ç®¡ç†ä»˜ãï¼‰

#### ğŸ“Š å‡¦ç†ã®æµã‚Œ
```mermaid
graph TD
    A["add_message called"] --> B["Validate role"]
    B -->|Invalid| C["Raise ValueError"]
    B -->|Valid| D["Create message object"]
    D --> E["Add to messages list"]
    E --> F{"Exceed message limit?"}
    F -->|Yes| G["Preserve developer msg"]
    G --> H["Truncate old messages"]
    F -->|No| I["Keep all messages"]
    H --> I
```

#### ğŸ“‹ IPOè¨­è¨ˆ

| é …ç›® | å†…å®¹ |
|------|------|
| **INPUT** | `role: RoleType` - ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¹å‰²<br>`content: str` - ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ |
| **PROCESS** | å½¹å‰²æ¤œè¨¼ â†’ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆ â†’ è¿½åŠ  â†’ åˆ¶é™ç¢ºèª â†’ å¿…è¦ã«å¿œã˜ã¦åˆ‡ã‚Šè©°ã‚ |
| **OUTPUT** | `None` - å‰¯ä½œç”¨ã¨ã—ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´æ›´æ–° |

#### ğŸ­ å½¹å‰²æ¤œè¨¼ãƒ»åˆ¶é™ç®¡ç†

```python
valid_roles: List[RoleType] = ["user", "assistant", "system", "developer"]

# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸åˆ¶é™ç®¡ç†
limit = config.get("api.message_limit", 50)
if len(self._messages) > limit:
    # æœ€åˆã®developerãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ä¿æŒ
    developer_msg = self._messages[0] if self._messages[0]['role'] == 'developer' else None
    self._messages = self._messages[-limit:]
    if developer_msg and self._messages[0]['role'] != 'developer':
        self._messages.insert(0, developer_msg)
```

---

### ğŸ”¢ TokenManager.count_tokens()

#### ğŸ¯ å‡¦ç†æ¦‚è¦
tiktokenãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ãŸç²¾å¯†ãªãƒˆãƒ¼ã‚¯ãƒ³æ•°è¨ˆç®—

#### ğŸ“Š å‡¦ç†ã®æµã‚Œ
```mermaid
graph TD
    A["count_tokens called"] --> B["Set default model"]
    B --> C["Get encoding name from MODEL_ENCODINGS"]
    C --> D["Get tiktoken encoding"]
    D --> E["Encode text to tokens"]
    E --> F["Return token count"]
    D -->|Error| G["Fallback: Simple estimation"]
    G --> H["Return estimated count"]
```

#### ğŸ“‹ IPOè¨­è¨ˆ

| é …ç›® | å†…å®¹ |
|------|------|
| **INPUT** | `text: str` - ãƒˆãƒ¼ã‚¯ãƒ³è¨ˆç®—å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ<br>`model: str = None` - ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«å |
| **PROCESS** | ãƒ¢ãƒ‡ãƒ«ç¢ºèª â†’ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å–å¾— â†’ tiktokenè¨ˆç®— â†’ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾å¿œ |
| **OUTPUT** | `int` - ç²¾å¯†ãªãƒˆãƒ¼ã‚¯ãƒ³æ•° |

#### ğŸ¯ ãƒ¢ãƒ‡ãƒ«å¯¾å¿œãƒ»ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

```python
MODEL_ENCODINGS = {
    "gpt-4o": "cl100k_base",
    "gpt-4o-mini": "cl100k_base",
    "gpt-4.1": "cl100k_base",
    "gpt-4.1-mini": "cl100k_base",
    "o1": "cl100k_base",
    # ... ä»–ã®ãƒ¢ãƒ‡ãƒ«
}

# ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨ˆç®—
try:
    enc = tiktoken.get_encoding(encoding_name)
    return len(enc.encode(text))
except Exception:
    # ç°¡æ˜“æ¨å®šï¼ˆ1æ–‡å­— = 0.5ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰
    return len(text) // 2
```

---

### ğŸ“‹ ResponseProcessor.extract_text()

#### ğŸ¯ å‡¦ç†æ¦‚è¦
OpenAI Responses APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã®æŠ½å‡º

#### ğŸ“Š å‡¦ç†ã®æµã‚Œ
```mermaid
graph TD
    A["Response object"] --> B{"Has output attribute?"}
    B -->|Yes| C["Iterate output items"]
    C --> D{"Item type is message?"}
    D -->|Yes| E["Iterate content"]
    E --> F{"Content type is output_text?"}
    F -->|Yes| G["Extract text"]
    B -->|No| H{"Has output_text attribute?"}
    H -->|Yes| I["Add to texts list"]
    G --> J["Return texts list"]
    I --> J
```

#### ğŸ“‹ IPOè¨­è¨ˆ

| é …ç›® | å†…å®¹ |
|------|------|
| **INPUT** | `response: Response` - OpenAI Responses APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ |
| **PROCESS** | éšå±¤æ§‹é€ ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ â†’ ãƒ†ã‚­ã‚¹ãƒˆè¦ç´ æŠ½å‡º â†’ ãƒªã‚¹ãƒˆé›†ç´„ |
| **OUTPUT** | `List[str]` - æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆ |

#### ğŸ” ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ è§£æ

```python
# Responses APIæ§‹é€ 
response.output[i].content[j].text
                    â†“
# æŠ½å‡ºå¯¾è±¡ï¼štype="output_text" ã®ãƒ†ã‚­ã‚¹ãƒˆ

# ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
response.output_text  # ç›´æ¥å±æ€§ãŒã‚ã‚‹å ´åˆ
```

---

### ğŸ¤– OpenAIClient.create_response()

#### ğŸ¯ å‡¦ç†æ¦‚è¦
Responses APIå‘¼ã³å‡ºã—ï¼ˆæ–°æ—§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä»•æ§˜å¯¾å¿œï¼‰

#### ğŸ“Š å‡¦ç†ã®æµã‚Œ
```mermaid
graph TD
    A["create_response called"] --> B["Set default model"]
    B --> C["Check input parameter"]
    C --> D{"input is None?"}
    D -->|Yes| E["Use messages parameter"]
    E --> F{"Both None?"}
    F -->|Yes| G["Raise ValueError"]
    D -->|No| H["Use input parameter"]
    F -->|No| I["Prepare API parameters"]
    H --> I
    G --> J["Error"]
    I --> K["Call OpenAI Responses API"]
    K --> L["Return Response object"]
```

#### ğŸ“‹ IPOè¨­è¨ˆ

| é …ç›® | å†…å®¹ |
|------|------|
| **INPUT** | `messages: List[EasyInputMessageParam] = None` - æ—§ä»•æ§˜<br>`input: List[EasyInputMessageParam] = None` - æ–°ä»•æ§˜<br>`model: str = None` - ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«<br>`**kwargs` - ãã®ä»–APIãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ |
| **PROCESS** | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿çµ±ä¸€ â†’ ãƒ¢ãƒ‡ãƒ«è¨­å®š â†’ APIå‘¼ã³å‡ºã— |
| **OUTPUT** | `Response` - OpenAI Responses APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ |

#### ğŸ”„ æ–°æ—§ä»•æ§˜å¯¾å¿œ

```python
# æ–°æ—§ä¸¡æ–¹ã®å¼•æ•°åã‚’ã‚µãƒãƒ¼ãƒˆ
if input is None:
    input = messages  # æ—§ä»•æ§˜ â†’ æ–°ä»•æ§˜å¤‰æ›
if input is None:
    raise ValueError("messages or input must be provided")

params = {
    "model": model,
    "input": input,  # çµ±ä¸€å¾Œã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
}
```

---

## âš™ï¸ æŠ€è¡“ä»•æ§˜

### ğŸ“¦ ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒª

| ãƒ©ã‚¤ãƒ–ãƒ©ãƒª | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | ç”¨é€” | é‡è¦åº¦ |
|-----------|-----------|------|---------|
| `openai` | æœ€æ–° | ğŸ¤– OpenAI APIå…¬å¼ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ | â­â­â­ |
| `tiktoken` | æœ€æ–° | ğŸ”¢ ç²¾å¯†ãªãƒˆãƒ¼ã‚¯ãƒ³è¨ˆç®— | â­â­â­ |
| `yaml` | æœ€æ–° | âš™ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç† | â­â­â­ |
| `re` | æ¨™æº– | ğŸ”¤ æ­£è¦è¡¨ç¾å‡¦ç† | â­â­ |
| `time` | æ¨™æº– | â° æ™‚é–“å‡¦ç†ãƒ»TTLç®¡ç† | â­â­â­ |
| `json` | æ¨™æº– | ğŸ“‹ JSONå‡¦ç† | â­â­â­ |
| `logging` | æ¨™æº– | ğŸ“ ãƒ­ã‚°ç®¡ç† | â­â­â­ |
| `os` | æ¨™æº– | ğŸ”§ ç’°å¢ƒå¤‰æ•°ãƒ»OSæ“ä½œ | â­â­ |
| `pathlib` | æ¨™æº– | ğŸ“ ãƒ‘ã‚¹æ“ä½œ | â­â­ |
| `dataclasses` | æ¨™æº– | ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹å®šç¾© | â­ |
| `functools` | æ¨™æº– | ğŸ”§ é–¢æ•°ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ | â­â­ |
| `datetime` | æ¨™æº– | ğŸ“… æ—¥æ™‚å‡¦ç† | â­â­ |
| `abc` | æ¨™æº– | ğŸ—ï¸ æŠ½è±¡åŸºåº•ã‚¯ãƒ©ã‚¹ | â­ |
| `hashlib` | æ¨™æº– | ğŸ” ãƒãƒƒã‚·ãƒ¥è¨ˆç®— | â­â­ |

### ğŸ¤– OpenAI APIå¯¾å¿œä»•æ§˜

#### ğŸ“‹ å¯¾å¿œAPI

```yaml
Supported_APIs:
  responses_api:
    description: "OpenAI Responses API (æ–°ä»•æ§˜)"
    method: "client.responses.create()"
    input_format: "List[EasyInputMessageParam]"
    backward_compatibility: "messages parameteræ”¯æ´"

  chat_completions_api:
    description: "OpenAI Chat Completions API"
    method: "client.chat.completions.create()"
    input_format: "List[ChatCompletionMessageParam]"
    features: "æ¨™æº–çš„ãªä¼šè©±API"
```

#### ğŸ­ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‹å®šç¾©

```python
# Responses APIç”¨
EasyInputMessageParam: æ–°ä»•æ§˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‹
ResponseInputTextParam: ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›å‹
ResponseInputImageParam: ç”»åƒå…¥åŠ›å‹

# Chat Completions APIç”¨
ChatCompletionSystemMessageParam: ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
ChatCompletionUserMessageParam: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
ChatCompletionAssistantMessageParam: ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

# å½¹å‰²å‹
RoleType = Literal["user", "assistant", "system", "developer"]
```

### âš™ï¸ è¨­å®šç®¡ç†ä»•æ§˜

#### ğŸ“„ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ï¼ˆconfig.ymlï¼‰

```yaml
models:
  default: "gpt-4o-mini"
  available: ["gpt-4o-mini", "gpt-4o", "gpt-4.1", "gpt-4.1-mini"]

api:
  timeout: 30
  max_retries: 3
  openai_api_key: null  # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—

ui:
  page_title: "OpenAI API Demo"
  page_icon: "ğŸ¤–"
  layout: "wide"

cache:
  enabled: true
  ttl: 3600
  max_size: 100

logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: null
  max_bytes: 10485760
  backup_count: 5

error_messages:
  general_error: "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
  api_key_missing: "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
  network_error: "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"

experimental:
  debug_mode: false
  performance_monitoring: true
```

#### ğŸ”§ ç’°å¢ƒå¤‰æ•°ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰

```yaml
Environment_Variables:
  OPENAI_API_KEY: "api.openai_api_key"
  LOG_LEVEL: "logging.level"
  DEBUG_MODE: "experimental.debug_mode"
```

### ğŸ’¾ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ä»•æ§˜

#### ğŸ”§ ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š

```yaml
Cache_Configuration:
  type: "Memory-based"
  ttl: 3600  # seconds
  max_size: 100  # entries
  eviction_policy: "LRU (oldest timestamp)"
  storage_format:
    key: "function_name_hash"
    value:
      result: "Any"
      timestamp: "float"
```

#### ğŸ“Š ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ç”Ÿæˆ

```python
ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯:
1. é–¢æ•°åå–å¾—: func.__name__
2. å¼•æ•°ãƒãƒƒã‚·ãƒ¥åŒ–: hashlib.md5(str(args) + str(kwargs))
3. çµåˆ: f"{function_name}_{hash}"

ä¾‹: get_completion(model="gpt-4o", temp=0.7)
â†’ "get_completion_a1b2c3d4e5f6789..."
```

### ğŸ”¢ ãƒˆãƒ¼ã‚¯ãƒ³ç®¡ç†ä»•æ§˜

#### ğŸ“‹ ãƒ¢ãƒ‡ãƒ«å¯¾å¿œè¡¨

```yaml
Model_Encodings:
  gpt-4o: "cl100k_base"
  gpt-4o-mini: "cl100k_base"
  gpt-4o-audio-preview: "cl100k_base"
  gpt-4o-mini-audio-preview: "cl100k_base"
  gpt-4.1: "cl100k_base"
  gpt-4.1-mini: "cl100k_base"
  o1: "cl100k_base"
  o1-mini: "cl100k_base"
  o3: "cl100k_base"
  o3-mini: "cl100k_base"
  o4: "cl100k_base"
  o4-mini: "cl100k_base"
```

#### ğŸ’° æ–™é‡‘è¨ˆç®—ä»•æ§˜

```python
æ–™é‡‘è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯:
input_cost = (input_tokens / 1000) * model_pricing["input"]
output_cost = (output_tokens / 1000) * model_pricing["output"]
total_cost = input_cost + output_cost

# ãƒ¢ãƒ‡ãƒ«æ–™é‡‘ã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯AppConfigã‹ã‚‰å–å¾—
```

### ğŸ“Š ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†ä»•æ§˜

#### ğŸ”„ JSON ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³

```yaml
Serialization_Rules:
  pydantic_model: "obj.model_dump()"
  dict_protocol: "obj.dict()"
  datetime_object: "obj.isoformat()"
  openai_usage: "manual_attribute_extraction"
  fallback: "str(obj)"
```

#### ğŸ’¾ ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä¿å­˜

```yaml
Response_Save_Format:
  filename: "response_{timestamp}.json"
  directory: "logs/"
  structure:
    id: "response.id"
    model: "response.model"
    created_at: "response.created_at"
    text: "List[extracted_text]"
    usage: "serialized_usage_object"
```

---

## ğŸš¨ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### ğŸ“‹ ã‚¨ãƒ©ãƒ¼ã‚«ãƒ†ã‚´ãƒª

#### âš™ï¸ è¨­å®šé–¢é€£ã‚¨ãƒ©ãƒ¼

| ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥ | åŸå›  | å¯¾å‡¦æ³• | å½±éŸ¿åº¦ |
|-----------|------|--------|---------|
| **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¸åœ¨** | ğŸ“„ config.ymlãƒ•ã‚¡ã‚¤ãƒ«ãªã— | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§å‹•ä½œç¶™ç¶šãƒ»è­¦å‘Šè¡¨ç¤º | ğŸŸ¡ ä¸­ |
| **YAMLå½¢å¼ã‚¨ãƒ©ãƒ¼** | ğŸ”¤ ä¸æ­£ãªYAMLè¨˜æ³• | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ»ã‚¨ãƒ©ãƒ¼è©³ç´°è¡¨ç¤º | ğŸŸ¡ ä¸­ |
| **APIã‚­ãƒ¼æœªè¨­å®š** | ğŸ”‘ ç’°å¢ƒå¤‰æ•°ãƒ»è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¸¡æ–¹ãªã— | æ˜ç¢ºãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ»è¨­å®šæŒ‡ç¤º | ğŸ”´ é«˜ |
| **è¨­å®šå€¤å‹ã‚¨ãƒ©ãƒ¼** | ğŸ”¢ æœŸå¾…ã—ãªã„å‹ã®è¨­å®šå€¤ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ä½¿ç”¨ãƒ»è­¦å‘Šãƒ­ã‚° | ğŸŸ  ä½ |

#### ğŸ¤– APIé–¢é€£ã‚¨ãƒ©ãƒ¼

| ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥ | åŸå›  | å¯¾å‡¦æ³• | å½±éŸ¿åº¦ |
|-----------|------|--------|---------|
| **èªè¨¼ã‚¨ãƒ©ãƒ¼** | ğŸ”‘ ä¸æ­£ãªAPIã‚­ãƒ¼ | APIã‚­ãƒ¼ç¢ºèªæŒ‡ç¤ºãƒ»ä¾‹å¤–å†ç™ºç”Ÿ | ğŸ”´ é«˜ |
| **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼** | ğŸŒ æ¥ç¶šãƒ»ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ | ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ãƒ»ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç¢ºèªæŒ‡ç¤º | ğŸŸ¡ ä¸­ |
| **APIãƒ¬ãƒ¼ãƒˆåˆ¶é™** | â±ï¸ OpenAIãƒ¬ãƒ¼ãƒˆåˆ¶é™åˆ°é” | é©åˆ‡ãªå¾…æ©Ÿæ™‚é–“ãƒ»æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ• | ğŸŸ¡ ä¸­ |
| **ç„¡åŠ¹ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆ** | ğŸ“‹ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»å½¢å¼ã‚¨ãƒ©ãƒ¼ | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¤œè¨¼ãƒ»è©³ç´°ã‚¨ãƒ©ãƒ¼æƒ…å ± | ğŸŸ¡ ä¸­ |
| **ãƒ¢ãƒ‡ãƒ«ä¸å­˜åœ¨** | ğŸ¤– æŒ‡å®šãƒ¢ãƒ‡ãƒ«åˆ©ç”¨ä¸å¯ | ãƒ¢ãƒ‡ãƒ«ä¸€è¦§è¡¨ç¤ºãƒ»ä»£æ›¿ææ¡ˆ | ğŸŸ¡ ä¸­ |

#### ğŸ’¾ ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢é€£ã‚¨ãƒ©ãƒ¼

| ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥ | åŸå›  | å¯¾å‡¦æ³• | å½±éŸ¿åº¦ |
|-----------|------|--------|---------|
| **JSONå‡¦ç†ã‚¨ãƒ©ãƒ¼** | ğŸ“‹ ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•— | safe_json_serializerä½¿ç”¨ãƒ»ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ | ğŸŸ¡ ä¸­ |
| **ãƒ•ã‚¡ã‚¤ãƒ«I/Oã‚¨ãƒ©ãƒ¼** | ğŸ“ æ¨©é™ãƒ»å­˜åœ¨ãƒ»å®¹é‡ã‚¨ãƒ©ãƒ¼ | æ¨©é™ç¢ºèªãƒ»ãƒ‘ã‚¹æ¤œè¨¼ãƒ»å®¹é‡ç¢ºèª | ğŸŸ¡ ä¸­ |
| **ãƒ¡ãƒ¢ãƒªä¸è¶³** | ğŸ’¾ å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç† | ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ãƒ»ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ææ¡ˆ | ğŸŸ¡ ä¸­ |
| **ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼** | ğŸ”¤ æ–‡å­—ã‚³ãƒ¼ãƒ‰å•é¡Œ | UTF-8å¼·åˆ¶ãƒ»ã‚¨ãƒ©ãƒ¼è©³ç´°è¡¨ç¤º | ğŸŸ  ä½ |

#### ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ é–¢é€£ã‚¨ãƒ©ãƒ¼

| ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥ | åŸå›  | å¯¾å‡¦æ³• | å½±éŸ¿åº¦ |
|-----------|------|--------|---------|
| **ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä¸åœ¨** | ğŸ“¦ å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« | ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æŒ‡ç¤ºãƒ»ä¾å­˜é–¢ä¿‚ç¢ºèª | ğŸ”´ é«˜ |
| **Pythonç’°å¢ƒã‚¨ãƒ©ãƒ¼** | ğŸ äº’æ›æ€§ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³å•é¡Œ | ç’°å¢ƒç¢ºèªæŒ‡ç¤ºãƒ»è¦ä»¶è¡¨ç¤º | ğŸ”´ é«˜ |
| **æ¨©é™ã‚¨ãƒ©ãƒ¼** | ğŸ”’ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¨©é™ä¸è¶³ | æ¨©é™è¨­å®šæŒ‡ç¤ºãƒ»ä»£æ›¿ãƒ‘ã‚¹ææ¡ˆ | ğŸŸ¡ ä¸­ |

### ğŸ› ï¸ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æˆ¦ç•¥

#### ğŸ”§ æ®µéšçš„ã‚¨ãƒ©ãƒ¼å‡¦ç†

```mermaid
graph TD
    A["Error Detected"] --> B{"Error Severity"}
    B -->|Critical| C["Immediate Termination"]
    B -->|High| D["Stop with Detailed Error"]
    B -->|Medium| E["Warning + Fallback"]
    B -->|Low| F["Log + Continue"]

    C --> G["System Error Message"]
    D --> H["API Error with Instructions"]
    E --> I["Default Configuration"]
    F --> J["Background Logging"]

    G --> K["Exit Application"]
    H --> L["User Action Required"]
    I --> M["Continue with Reduced Functionality"]
    J --> N["Normal Operation"]
```

#### ğŸ¯ ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿åˆ¥ã‚¨ãƒ©ãƒ¼å‡¦ç†

```python
# APIç”¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆä¾‹å¤–å†ç™ºç”Ÿï¼‰
@error_handler
def api_function():
    pass
# â†’ ãƒ­ã‚°å‡ºåŠ› + ä¾‹å¤–å†ç™ºç”Ÿï¼ˆå‘¼ã³å‡ºã—å…ƒã§å‡¦ç†ï¼‰

# ä¸€èˆ¬ç”¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆNoneè¿”å´ï¼‰
@safe_execute  # helper_rag.pyç‰ˆ
def safe_function():
    pass
# â†’ ãƒ­ã‚°å‡ºåŠ› + Noneè¿”å´ï¼ˆå‡¦ç†ç¶™ç¶šï¼‰

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–ï¼‰
@cache_result()
def cached_function():
    pass
# â†’ ã‚¨ãƒ©ãƒ¼æ™‚ã¯é–¢æ•°ã‚’ç›´æ¥å®Ÿè¡Œ
```

#### âœ… é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¾‹

```python
# è¨­å®šé–¢é€£ã‚¨ãƒ©ãƒ¼
logger.error("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: config.yml")
print("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§å‹•ä½œã‚’ç¶™ç¶šã—ã¾ã™")

# APIé–¢é€£ã‚¨ãƒ©ãƒ¼
logger.error(f"OpenAI API ã‚¨ãƒ©ãƒ¼: {str(e)}")
raise ValueError("APIã‚­ãƒ¼ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")

# ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼
logger.error(f"JSON serialization error: {e}")
# ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã§ç¶™ç¶š

# ã‚·ã‚¹ãƒ†ãƒ é–¢é€£ã‚¨ãƒ©ãƒ¼
logger.error(f"å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒä¸è¶³: {missing_lib}")
raise ImportError(f"pip install {missing_lib} ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
```

#### ğŸš¨ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥

```python
fallback_strategies = {
    "config_loading": {
        "action": "Use hardcoded defaults",
        "message": "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¸åœ¨ â†’ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§å‹•ä½œ"
    },
    "api_key_missing": {
        "action": "Raise clear error with instructions",
        "message": "ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„"
    },
    "tiktoken_error": {
        "action": "Simple character-based estimation",
        "message": "tiktokenå¤±æ•— â†’ ç°¡æ˜“æ¨å®šã«åˆ‡ã‚Šæ›¿ãˆ"
    },
    "json_serialization": {
        "action": "Convert to string representation",
        "message": "è¤‡é›‘ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ â†’ æ–‡å­—åˆ—å¤‰æ›ã§ä¿å­˜"
    },
    "cache_failure": {
        "action": "Disable caching, direct execution",
        "message": "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ– â†’ ç›´æ¥å®Ÿè¡Œã§ç¶™ç¶š"
    },
    "network_timeout": {
        "action": "Retry with exponential backoff",
        "message": "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å†è©¦è¡Œ â†’ æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•"
    }
}
```

#### ğŸ“Š ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«åˆ¥å‡¦ç†

```yaml
Log_Level_Strategy:
  CRITICAL:
    action: "System termination"
    notification: "Immediate alert"
    example: "OpenAI library not installed"

  ERROR:
    action: "Function failure"
    notification: "Error message display"
    example: "API authentication failed"

  WARNING:
    action: "Fallback execution"
    notification: "Warning display"
    example: "Config file not found, using defaults"

  INFO:
    action: "Normal operation"
    notification: "Progress logging"
    example: "API request completed in 2.3s"

  DEBUG:
    action: "Detailed tracing"
    notification: "Development logging"
    example: "Cache hit for key: user_123"
```

#### ğŸ”„ ãƒªãƒˆãƒ©ã‚¤æ©Ÿæ§‹

```python
retry_configuration = {
    "api_requests": {
        "max_retries": 3,
        "backoff_factor": 2,
        "retry_conditions": ["NetworkError", "TimeoutError", "RateLimitError"]
    },
    "file_operations": {
        "max_retries": 2,
        "backoff_factor": 1,
        "retry_conditions": ["PermissionError", "IOError"]
    },
    "json_operations": {
        "max_retries": 1,
        "backoff_factor": 1,
        "retry_conditions": ["UnicodeDecodeError"]
    }
}
```

---

## ğŸ‰ ã¾ã¨ã‚

ã“ã®è¨­è¨ˆæ›¸ã¯ã€**helper_api.py** ã®åŒ…æ‹¬çš„ãªæŠ€è¡“ä»•æ§˜ã¨å®Ÿè£…è©³ç´°ã‚’è¨˜è¼‰ã—ãŸå®Œå…¨ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã™ã€‚

### ğŸŒŸ è¨­è¨ˆã®ãƒã‚¤ãƒ©ã‚¤ãƒˆ

- **ğŸ¤– OpenAI APIç‰¹åŒ–**: Responses APIãƒ»Chat Completions APIå®Œå…¨å¯¾å¿œ
- **âš™ï¸ ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³è¨­å®šç®¡ç†**: YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ç’°å¢ƒå¤‰æ•°çµ±åˆç®¡ç†
- **ğŸ’¾ åŠ¹ç‡çš„ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°**: TTLãƒ»ã‚µã‚¤ã‚ºåˆ¶é™ä»˜ããƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥
- **ğŸ›¡ï¸ å …ç‰¢ãªã‚¨ãƒ©ãƒ¼å‡¦ç†**: æ®µéšçš„ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ»ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥
- **ğŸ”¢ ç²¾å¯†ãƒˆãƒ¼ã‚¯ãƒ³ç®¡ç†**: tiktokenä½¿ç”¨ãƒ»ãƒ¢ãƒ‡ãƒ«å¯¾å¿œãƒ»ã‚³ã‚¹ãƒˆæ¨å®š

### ğŸ”§ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç‰¹å¾´

- **ğŸ“¦ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–è¨­è¨ˆ**: æ©Ÿèƒ½åˆ¥ã‚¯ãƒ©ã‚¹ãƒ»è²¬å‹™åˆ†é›¢ãƒ»å†åˆ©ç”¨æ€§
- **ğŸ¯ ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿æ´»ç”¨**: æ¨ªæ–­çš„é–¢å¿ƒäº‹ã®åŠ¹ç‡çš„é©ç”¨
- **ğŸ”„ å¾Œæ–¹äº’æ›æ€§**: æ–°æ—§APIä»•æ§˜ä¸¡å¯¾å¿œãƒ»æ®µéšçš„ç§»è¡Œæ”¯æ´
- **ğŸ“Š JSONå®‰å…¨å‡¦ç†**: OpenAIç‹¬ç‰¹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å®Œå…¨å¯¾å¿œ

### ğŸ“ˆ OpenAI APIæœ€é©åŒ–æ©Ÿèƒ½

- **ğŸ­ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç®¡ç†**: å½¹å‰²æ¤œè¨¼ãƒ»å±¥æ­´åˆ¶é™ãƒ»ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
- **â±ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–**: å®Ÿè¡Œæ™‚é–“è¨ˆæ¸¬ãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹ç‡åŒ–
- **ğŸ’° ã‚³ã‚¹ãƒˆç®¡ç†**: ç²¾å¯†ãªãƒˆãƒ¼ã‚¯ãƒ³è¨ˆç®—ãƒ»æ–™é‡‘æ¨å®š
- **ğŸ“‹ ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†**: æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãƒ»å®‰å…¨ä¿å­˜

### ğŸš€ ä»Šå¾Œã®æ‹¡å¼µå¯èƒ½æ€§

- ğŸ”„ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°APIå¯¾å¿œ
- ğŸ“Š é«˜åº¦ãªåˆ†æãƒ»ç›£è¦–æ©Ÿèƒ½
- ğŸŒ åˆ†æ•£ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œ
- ğŸ“± ãƒ¢ãƒã‚¤ãƒ«ç’°å¢ƒæœ€é©åŒ–
- ğŸ” ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–æ©Ÿèƒ½
