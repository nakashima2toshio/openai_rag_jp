# config.yml（改修後）

models:
  default: "gpt-5-mini"
  available:
    - "gpt-4o"
    - "gpt-4o-mini"
    - "gpt-4.1"
    - "gpt-4.1-mini"
    - "o3"
    - "o4-mini"
    - "gpt-5"
    - "gpt-5-mini"
    - "gpt-5-nano"

  audio_default: "tts-1"

  categories:
    frontier: ["gpt-5", "gpt-5-mini", "gpt-5-nano"]              # GPT-5 系（最新）  [oai_citation:13‡OpenAI Platform](https://platform.openai.com/docs/models/compare?utm_source=chatgpt.com)
    reasoning: ["o3", "o4-mini", "o1", "o1-pro"]                  # o系推論モデル   [oai_citation:14‡OpenAI Platform](https://platform.openai.com/docs/models/o1?utm_source=chatgpt.com)
    deep_research: ["o3-deep-research", "o4-mini-deep-research"]  # 深い調査用      [oai_citation:15‡OpenAI Platform](https://platform.openai.com/docs/models/o3-deep-research?utm_source=chatgpt.com)
    standard: ["gpt-4o", "gpt-4o-mini", "gpt-4.1", "gpt-4.1-mini"]# 安定の汎用      [oai_citation:16‡OpenAI Platform](https://platform.openai.com/docs/models/gpt-4o?utm_source=chatgpt.com)
    vision: ["gpt-5", "gpt-4o", "gpt-4o-mini"]                    # 画像入力対応    [oai_citation:17‡OpenAI Platform](https://platform.openai.com/docs/models/gpt-5-chat-latest?utm_source=chatgpt.com)
    audio:
      - "gpt-4o-audio-preview"
      - "gpt-4o-mini-audio-preview"
      - "gpt-4o-transcribe"
      - "gpt-4o-mini-transcribe"  # 追加                  [oai_citation:18‡OpenAI Platform](https://platform.openai.com/docs/models/gpt-4o-mini-transcribe?utm_source=chatgpt.com)
      - "gpt-4o-mini-tts"
      - "tts-1"
      - "tts-1-hd"
      - "whisper-1"
    realtime: ["gpt-4o-realtime-preview", "gpt-4o-mini-realtime-preview"]  # Realtime   [oai_citation:19‡OpenAI Platform](https://platform.openai.com/docs/models?utm_source=chatgpt.com)
    image: ["gpt-image-1", "dall-e-3"]                                     # 画像生成   [oai_citation:20‡OpenAI Platform](https://platform.openai.com/docs/models/dall-e-3?utm_source=chatgpt.com)
    search: ["gpt-4o-search-preview", "gpt-4o-mini-search-preview"]        # Web検索    [oai_citation:21‡OpenAI Platform](https://platform.openai.com/docs/models/compare?utm_source=chatgpt.com)
    open_weight: ["gpt-oss-120b", "gpt-oss-20b"]                            # Open weight
    embeddings: ["text-embedding-3-large", "text-embedding-3-small", "text-embedding-ada-002"]
    moderation: ["omni-moderation-latest"]

samples:
  images:
    nature: "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
  prompts: {}
  audio:
    tts_example: "こんにちは、これはテキスト読み上げのテストです。"
    voice_agent_greeting: "音声エージェントのテストです。何かお手伝いできることはありますか？"
    transcription_test: "This is a test for speech-to-text functionality."

audio:
  voices: ["alloy", "nova", "echo", "onyx", "shimmer"]
  supported_formats: ["*.mp3", "*.wav", "*.m4a"]
  tts_max_chars: 4096
  voice_agent_system_prompt: "You are a friendly Japanese voice assistant. Respond in concise Japanese (≤2 sentences)."
  tts:
    default_voice: "alloy"
    streaming_enabled: true
    quality_settings:
      tts-1: "speed_optimized"
      tts-1-hd: "quality_optimized"
      gpt-4o-mini-tts: "gpt4o_enhanced"
  stt:
    response_format: "text"
    language: "ja"
    max_file_size_mb: 25
  realtime:
    default_format: "pcm16"
    vad_enabled: true
    sample_rate: 16000

model_pricing:
  tts-1:
    input: 0.015
    output: 0.0
  tts-1-hd:
    input: 0.030
    output: 0.0
  gpt-4o-mini-tts:
    input: 0.025
    output: 0.0
  whisper-1:
    input: 0.006
    output: 0.0
  gpt-4o-transcribe:
    input: 0.010
    output: 0.0
